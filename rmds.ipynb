{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Risk Measure DataSet generation engine codebase\n",
    "\n",
    "This engine contains the following key components (these are *the* prompts used for ChatGPT!):\n",
    "\n",
    "1.\tFirst, a *singleton* object, *CurveManager*, that contains a list of curves identifiable by name and date. Each curve is a specialization of an abstract Curve class and the simplest of which has a vector of double values itemized by dates and when the object is called with a date, an interpolated value is returned. \n",
    "\n",
    "2.\tSecond, a singleton object, *ScenarioManager*, that contains a list of market scenarios identifiable by name and date. Each scenario is constructed by taking the complete list of curves from the CurveManager as the BASE, and perturb each curve up and down in a certain fashion, so that the scenario will contain three lists of the curves: the BASE, the UP perturbed, and the DOWN perturbed.\n",
    "\n",
    "3.\tThirdly, a singleton object, *SecurityManager*, that contains a list of financial securities identifiable by an id. Each security is a specialization of an abstract class Security, constructed from a dictionary of <attribute, value>, and has a function, NPV, that takes a scenario object and returns a value.\n",
    "\n",
    "4.\tLast, a generic function that iterates through each security from the SecurityManager and each scenario from the ScenarioManager, and call the security's NPV function three times to obtain three values for each the perturbations contained in the scenario. The three values are then pushed into a data store with all the relevant identifiers.\n",
    "\n",
    "5.\tPiecing them together is a workflow manager, or *task dispatcher*, to use this code base: it takes a JSON document as a configuration input that instructs about where all the input files such as curve definition and security definition and the scenario definition are located, and indicates what use case the job is tasked with, then it will first pre-process the inputs and construct the three containers, CurveManager, ScenarioManager, and SecurityManager, and dispatch the workflow to the relevant use case. At the end, output the result in the data store to a CSV file.\n",
    "\n",
    "6.\tAnd one more item and most important to complete the picture: *info logging*! we now need a logger through the code so that each step is logged and if there is any exception, error messages are captured into the log. \n",
    "\n",
    "This file is the *architectural design master* document, also the POC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "from ast import Pow\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "from datetime import datetime\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Union, List, Optional, Tuple\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import csv\n",
    "import bisect\n",
    "import sys\n",
    "\n",
    "# Configure logging\n",
    "''' disable file logging for now\n",
    "logging.basicConfig(\n",
    "    filename=\"task_dispatcher.log\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "'''\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s %(levelname)s %(name)s %(process)d: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract Classes and Singleton Managers\n",
    "class Curve:\n",
    "    \"\"\"Abstract base class for a curve.\"\"\"\n",
    "    # concrete method to initialize meta data for the curve\n",
    "    def __init__(self, name: str, date:datetime):\n",
    "        self.name = name\n",
    "        self.date = date\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_value(self, date: int) -> float:\n",
    "        pass\n",
    "\n",
    "class SimpleCurve(Curve):\n",
    "    \"\"\"A simple curve with linear interpolation.\"\"\"\n",
    "    def __init__(self, name:str, date:datetime, dates: int, values: float):\n",
    "        super().__init__(name, date)\n",
    "        self.dates = np.array(dates)\n",
    "        self.values = np.array(values)\n",
    "        self.interpolator = interp1d(self.dates.astype(int), self.values, kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "    def geometric_interp(self, date: int) -> float:\n",
    "        # find the right point\n",
    "        idx = bisect.bisect_left(self.dates, date)\n",
    "\n",
    "        # init the two bounding points for interpolation \n",
    "        t0, t1 = self.dates[0], self.dates[1] \n",
    "        v0, v1 = self.values[0], self.values[1] \n",
    "        #handle edge case: flat, or extrapolate\n",
    "        if idx == 0:    #do not extrapolate leftward \n",
    "            return v0\n",
    "        elif idx == len(self.dates):    #extrapolate using the last two points\n",
    "            t0, t1 = self.dates[-2], self.dates[-1] \n",
    "            v0, v1 = self.values[-2], self.values[-1] \n",
    "\n",
    "        # otherwise\n",
    "        t0, t1 = self.dates[idx - 1], self.dates[idx] \n",
    "        v0, v1 = self.values[idx - 1], self.values[idx] \n",
    "\n",
    "        e = float((date - t0) / (t1 - t0))\n",
    "        # Perform geometric interpolation \n",
    "        return v0 * pow((v1 / v0), e)\n",
    "\n",
    "    def get_value(self, date: int) -> float:\n",
    "        return self.geometric_interp(date) # self.interpolator(date)\n",
    "\n",
    "class CurveManager:\n",
    "    \"\"\"Singleton class managing curves.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(CurveManager, cls).__new__(cls)\n",
    "            cls._instance.curves = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date: datetime):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    # use read_curves_from_csv instead\n",
    "    def load_curves(self, curve_file):\n",
    "        self.read_curves_from_csv(curve_file)\n",
    "        '''\n",
    "        curves_data = pd.read_csv(curve_file)\n",
    "        for _, row in curves_data.iterrows():\n",
    "            dates = [datetime.strptime(d, \"%Y-%m-%d\") for d in row[\"dates\"].split(\";\")]\n",
    "            values = [float(v) for v in row[\"values\"].split(\";\")]\n",
    "            self.add_curve(SimpleCurve(name=row[\"curve_name\"], date=self.valuation_date, dates=dates, values=values))\n",
    "        '''\n",
    "        \n",
    "    def read_curves_from_csv(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                curve_name = None\n",
    "                curve_date = self.valuation_date\n",
    "                curve_type = None\n",
    "                dates = []\n",
    "                values = []\n",
    "\n",
    "                for row in reader:\n",
    "                    if not row:  # Blank row indicates end of current curve\n",
    "                        if curve_name and dates and values:\n",
    "                            curve = SimpleCurve(curve_name, curve_date, dates, values)\n",
    "                            self.add_curve(curve)\n",
    "                            curve_name = None\n",
    "                            dates = []\n",
    "                            values = []\n",
    "                    elif curve_name is None:  # Header row containing curve name\n",
    "                        curve_name = row[0]\n",
    "                        curve_date = datetime.strptime(row[1], '%Y%m%d')\n",
    "                        curve_type = row[2]\n",
    "                    else:  # Data rows containing <date, discount factor>\n",
    "                        date = int(row[0])\n",
    "                        value = float(row[1])\n",
    "                        dates.append(date)\n",
    "                        values.append(value)\n",
    "\n",
    "                # Add the last curve if the file doesn't end with a blank row\n",
    "                if curve_name and dates and values:\n",
    "                    curve = SimpleCurve(curve_name, curve_date, dates, values)\n",
    "                    self.add_curve(curve)\n",
    "                    \n",
    "            logging.info(f\"Successfully read and added curves from CSV: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading curves from CSV file {file_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_curve(self, curve: Curve):\n",
    "        key = (curve.name,curve.date)\n",
    "        self.curves[key] = curve\n",
    "        logging.info(f\"Added curve: {curve.name}\")\n",
    "\n",
    "    def get_curve(self, name: str, date:datetime) -> Optional[Curve]:\n",
    "        return self.curves.get((name,date))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scenario:\n",
    "    \"\"\"Class representing a market scenario with BASE, UP, and DOWN perturbed curves.\"\"\"\n",
    "    def __init__(self, name: str, date: datetime, base_curves: Dict[Tuple[str], Curve]):\n",
    "        self.name = name\n",
    "        self.date = date\n",
    "        self.base_curves = base_curves\n",
    "        self.up_curves = {}\n",
    "        self.down_curves = {}\n",
    "        self._generate_perturbations()\n",
    "\n",
    "    def _generate_perturbations(self):\n",
    "        \"\"\"Generates UP and DOWN perturbed curves.\"\"\"\n",
    "        for key, curve in self.base_curves.items():\n",
    "            up_values = [v * 1.1 for v in curve.values]\n",
    "            down_values = [v * 0.9 for v in curve.values]\n",
    "            self.up_curves[key] = SimpleCurve(curve.name, curve.date, curve.dates, up_values)\n",
    "            self.down_curves[key] = SimpleCurve(curve.name, curve.date, curve.dates, down_values)\n",
    "\n",
    "\n",
    "class ScenarioManager:\n",
    "    \"\"\"Singleton class managing scenarios.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(ScenarioManager, cls).__new__(cls)\n",
    "            cls._instance.scenarios = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    def create_scenario(self, name: str, date: datetime):\n",
    "        curve_manager = CurveManager()\n",
    "        base_curves = curve_manager.curves\n",
    "        scenario = Scenario(name, date, base_curves)\n",
    "        self.scenarios[(name, date)] = scenario\n",
    "        logging.info(f\"Created scenario: {name} on {date}\")\n",
    "\n",
    "    def load_scenarios(self, scenario_file):\n",
    "        # just the BASE for now\n",
    "        # scenarios_data = pd.read_csv(scenario_file)\n",
    "        logging.info(f\"Start loading scenarios: first the BASE curves\")\n",
    "        self.create_scenario(\"BASE\", self.valuation_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Security(ABC):\n",
    "    \"\"\"Abstract class for a financial security.\"\"\"\n",
    "    def __init__(self, security_id: str, attributes: Dict[str, Union[str, float, int]]):\n",
    "        self.security_id = security_id\n",
    "        self.attributes = attributes\n",
    "        self.setup_security()\n",
    "\n",
    "    @abstractmethod\n",
    "    def setup_security(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Bond(Security):\n",
    "    \"\"\"A simple bond implementation.\"\"\"\n",
    "    def __init__(self, security_id, attributes):\n",
    "        super().__init__(security_id, attributes)\n",
    "\n",
    "    def setup_security(self):\n",
    "        self.cashflow_dates = [1, 5, 7]\n",
    "        self.cashflor_values = [100,120,100100]\n",
    "\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        curve_name = (self.attributes[\"DiscountCurve\"],)\n",
    "        base_curve = scenario.base_curves.get(curve_name, scenario.date)\n",
    "\n",
    "        if not base_curve:\n",
    "            raise ValueError(f\"Curve {curve_name} not found in scenario.\")\n",
    "\n",
    "        npv = 0.0\n",
    "        for i in range(0,2):\n",
    "            discount_factor = base_curve.get_value(self.cashflow_dates[i])\n",
    "            npv += self.cashflor_values[i] * discount_factor\n",
    "        return npv\n",
    "\n",
    "class Equity(Security):\n",
    "    def __init__(self, security_id, attributes):\n",
    "        super().__init__(security_id, attributes)\n",
    "\n",
    "    def setup_security(self):\n",
    "        pass\n",
    "\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        # Implement equity-specific NPV calculation\n",
    "        npv = 0\n",
    "        for curve_name, curve in scenario.base_curves.items():\n",
    "            # Custom logic for NPV calculation for equities\n",
    "            npv += sum(curve.values)  # Simplified example\n",
    "        return npv\n",
    "\n",
    "class SecurityManager:\n",
    "    \"\"\"Singleton class managing securities.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(SecurityManager, cls).__new__(cls)\n",
    "            cls._instance.securities = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    def add_security(self, security: Security):\n",
    "        self.securities[security.security_id] = security\n",
    "        logging.info(f\"Added security: {security.security_id}\")\n",
    "\n",
    "    def construct_and_add_security(self, attributes: dict) -> int:\n",
    "        security_type = attributes.pop(\"SecType\", None)\n",
    "        security_id = attributes.get(\"SecId\")\n",
    "\n",
    "        if security_type == \"Bond\":\n",
    "            security = Bond(security_id, attributes)\n",
    "        elif security_type == \"equity\":\n",
    "            security = Equity(security_id, attributes)\n",
    "        else:\n",
    "            logging.error(f\"Unknown security type: {security_type}\")\n",
    "            return -1\n",
    "\n",
    "        self.add_security(security)\n",
    "        logging.info(f\"Constructed and added security of type {security_type}: {security_id}\")\n",
    "        return 0\n",
    "\n",
    "    def read_securities_from_tsv(self, file_path):\n",
    "        cnt1 = int(0)\n",
    "        cnt2 = int(0)\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                reader = csv.DictReader(file, delimiter='\\t')\n",
    "                for row in reader:\n",
    "                    attributes = dict(row)\n",
    "                    cnt2 += self.construct_and_add_security(attributes)\n",
    "                    cnt1 += 1\n",
    "\n",
    "            logging.info(f\"Successfully read {cnt1} rows and added {cnt1+cnt2} securities from TSV: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading securities from TSV file {file_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load_securities(self, security_file):\n",
    "        self.read_securities_from_tsv(security_file)\n",
    "        '''\n",
    "        securities_data = pd.read_csv(security_file)\n",
    "        for _, row in securities_data.iterrows():\n",
    "            attributes = {\n",
    "                \"curve_name\": row[\"curve_name\"],\n",
    "                \"cash_flows\": [\n",
    "                    (datetime.strptime(d, \"%Y-%m-%d\"), float(a))\n",
    "                    for d, a in zip(row[\"cash_flow_dates\"].split(\";\"), row[\"cash_flow_amounts\"].split(\";\"))\n",
    "                ]\n",
    "            }\n",
    "            self.add_security(Bond(security_id=row[\"security_id\"], attributes=attributes))\n",
    "        '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-10 21:20:56,408 INFO root 3448: Starting Task Dispatcher...\n",
      "2024-12-10 21:20:56,411 INFO root 3448: Added curve: OIS.USD\n",
      "2024-12-10 21:20:56,413 INFO root 3448: Added curve: OIS_LIBOR.USD\n",
      "2024-12-10 21:20:56,414 INFO root 3448: Successfully read and added curves from CSV: C:/dev/Python/rmds/tests\\curves.csv\n",
      "2024-12-10 21:20:56,414 INFO root 3448: Curves loaded\n",
      "2024-12-10 21:20:56,415 INFO root 3448: Start loading scenarios: first the BASE curves\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-10 21:20:56,419 INFO root 3448: Created scenario: BASE on 2024-06-30 00:00:00\n",
      "2024-12-10 21:20:56,422 INFO root 3448: Scenarios loaded\n",
      "2024-12-10 21:20:56,427 INFO root 3448: Added security: 3480191_0\n",
      "2024-12-10 21:20:56,430 INFO root 3448: Constructed and added security of type Bond: 3480191_0\n",
      "2024-12-10 21:20:56,431 ERROR root 3448: Unknown security type: FloatBond\n",
      "2024-12-10 21:20:56,432 ERROR root 3448: Unknown security type: MFixedLeg\n",
      "2024-12-10 21:20:56,433 ERROR root 3448: Unknown security type: MFloatLeg\n",
      "2024-12-10 21:20:56,434 ERROR root 3448: Unknown security type: MFixedLeg\n",
      "2024-12-10 21:20:56,434 INFO root 3448: Successfully read 5 rows and added 1 securities from TSV: C:/dev/Python/rmds/tests\\securities.tsv\n",
      "2024-12-10 21:20:56,435 INFO root 3448: Securities loaded\n",
      "2024-12-10 21:20:56,436 ERROR root 3448: Error calculating NPV for Security: 3480191_0, Scenario: BASE. Error: 'datetime.datetime' object has no attribute 'get_value'\n",
      "2024-12-10 21:20:56,439 INFO root 3448: Results saved to results.csv\n",
      "2024-12-10 21:20:56,440 INFO root 3448: Task Dispatcher completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Generic Calculation Function\n",
    "def calculate_npv_for_all(security_manager: SecurityManager, scenario_manager: ScenarioManager) -> pd.DataFrame:\n",
    "    data_store = []\n",
    "    for (scenario_name, scenario_date), scenario in scenario_manager.scenarios.items():\n",
    "        for security_id, security in security_manager.securities.items():\n",
    "            try:\n",
    "                base_npv = security.NPV(scenario)\n",
    "                up_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.up_curves))\n",
    "                down_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.down_curves))\n",
    "                data_store.append({\n",
    "                    \"Security ID\": security_id,\n",
    "                    \"Scenario Name\": scenario_name,\n",
    "                    \"Scenario Date\": scenario_date,\n",
    "                    \"NPV_BASE\": base_npv,\n",
    "                    \"NPV_UP\": up_npv,\n",
    "                    \"NPV_DOWN\": down_npv,\n",
    "                })\n",
    "                logging.info(f\"Calculated NPVs for Security: {security_id}, Scenario: {scenario_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error calculating NPV for Security: {security_id}, Scenario: {scenario_name}. Error: {e}\")\n",
    "    return pd.DataFrame(data_store)\n",
    "\n",
    "# Task Dispatcher\n",
    "from os import path\n",
    "class TaskDispatcher:\n",
    "    def __init__(self, config_file: str):\n",
    "        with open(config_file, 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "        self.wk_folder = path.dirname(config_file)\n",
    "        self.valuation_date = datetime.strptime(self.config[\"valuation_date\"], \"%Y-%m-%d\")\n",
    "        self.curve_manager = CurveManager()\n",
    "        self.curve_manager.set_valuation_date(self.valuation_date)\n",
    "        self.scenario_manager = ScenarioManager()\n",
    "        self.scenario_manager.set_valuation_date(self.valuation_date)\n",
    "        self.security_manager = SecurityManager()\n",
    "        self.security_manager.set_valuation_date(self.valuation_date)\n",
    "\n",
    "    def load_curves(self):\n",
    "        curve_file = self.config[\"curve_definition_file\"]\n",
    "        self.curve_manager.load_curves(path.join(self.wk_folder, curve_file))\n",
    "\n",
    "    def load_scenarios(self):\n",
    "        scenario_file = self.config[\"scenario_definition_file\"]\n",
    "        self.scenario_manager.load_scenarios(path.join(self.wk_folder, scenario_file))\n",
    "\n",
    "    def load_securities(self):\n",
    "        security_file = self.config[\"security_definition_file\"]\n",
    "        self.security_manager.load_securities(path.join(self.wk_folder, security_file))\n",
    "\n",
    "    def execute_use_case(self):\n",
    "        use_case = self.config[\"use_case\"]\n",
    "        if use_case == \"NPV_CALCULATION\":\n",
    "            results = calculate_npv_for_all(self.security_manager, self.scenario_manager)\n",
    "            results.to_csv(path.join(self.wk_folder, self.config[\"output_file\"]), index=False)\n",
    "            logging.info(f\"Results saved to {self.config['output_file']}\")\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            logging.info(\"Starting Task Dispatcher...\")\n",
    "            self.load_curves()\n",
    "            logging.info(\"Curves loaded\")\n",
    "            self.load_scenarios()\n",
    "            logging.info(\"Scenarios loaded\")\n",
    "            self.load_securities()\n",
    "            logging.info(\"Securities loaded\")\n",
    "            self.execute_use_case()\n",
    "            logging.info(\"Task Dispatcher completed successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Task Dispatcher encountered an error: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the configuration file\n",
    "    config_file = \"C:/dev/Python/rmds/tests/config.json\"\n",
    "    \n",
    "    # Initialize and run the TaskDispatcher\n",
    "    dispatcher = TaskDispatcher(config_file)\n",
    "    dispatcher.run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
