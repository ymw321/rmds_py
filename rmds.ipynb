{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Risk Measure DataSet generation engine codebase\n",
    "\n",
    "This engine contains the following key components (these are *the* prompts used for ChatGPT!):\n",
    "\n",
    "1.\tFirst, a *singleton* object, *CurveManager*, that contains a list of curves identifiable by name and date. Each curve is a specialization of an abstract Curve class and the simplest of which has a vector of double values itemized by dates and when the object is called with a date, an interpolated value is returned. \n",
    "\n",
    "2.\tSecond, a singleton object, *ScenarioManager*, that contains a list of market scenarios identifiable by name and date. Each scenario is constructed by taking the complete list of curves from the CurveManager as the BASE, and perturb each curve up and down in a certain fashion, so that the scenario will contain three lists of the curves: the BASE, the UP perturbed, and the DOWN perturbed.\n",
    "\n",
    "3.\tThirdly, a singleton object, *SecurityManager*, that contains a list of financial securities identifiable by an id. Each security is a specialization of an abstract class Security, constructed from a dictionary of <attribute, value>, and has a function, NPV, that takes a scenario object and returns a value.\n",
    "\n",
    "4.\tLast, a generic function that iterates through each security from the SecurityManager and each scenario from the ScenarioManager, and call the security's NPV function three times to obtain three values for each the perturbations contained in the scenario. The three values are then pushed into a data store with all the relevant identifiers.\n",
    "\n",
    "5.\tPiecing them together is a workflow manager, or *task dispatcher*, to use this code base: it takes a JSON document as a configuration input that instructs about where all the input files such as curve definition and security definition and the scenario definition are located, and indicates what use case the job is tasked with, then it will first pre-process the inputs and construct the three containers, CurveManager, ScenarioManager, and SecurityManager, and dispatch the workflow to the relevant use case. At the end, output the result in the data store to a CSV file.\n",
    "\n",
    "6.\tAnd one more item and most important to complete the picture: *info logging*! we now need a logger through the code so that each step is logged and if there is any exception, error messages are captured into the log. \n",
    "\n",
    "This file is the *architectural design master* document, also the POC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "from ast import Pow\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "from datetime import datetime\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Union, List, Optional, Tuple\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import csv\n",
    "import bisect\n",
    "import sys\n",
    "\n",
    "# Configure logging\n",
    "''' disable file logging for now\n",
    "logging.basicConfig(\n",
    "    filename=\"task_dispatcher.log\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "'''\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s %(levelname)s %(name)s %(process)d: %(message)s')\n",
    "\n",
    "# Abstract Classes and Singleton Managers\n",
    "class Curve:\n",
    "    \"\"\"Abstract base class for a curve.\"\"\"\n",
    "    def __init__(self, name: str, dates: List[datetime], values: List[float]):\n",
    "        self.name = name\n",
    "        self.dates = dates\n",
    "        self.values = values\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_value(self, date: datetime) -> float:\n",
    "        pass\n",
    "\n",
    "class SimpleCurve(Curve):\n",
    "    \"\"\"A simple curve with linear interpolation.\"\"\"\n",
    "    def __init__(self, dates: int, values: float):\n",
    "        self.dates = np.array(dates)\n",
    "        self.values = np.array(values)\n",
    "        self.interpolator = interp1d(self.dates.astype(int), self.values, kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "    def geometric_interp(self, date: int) -> float:\n",
    "        # find the right point\n",
    "        idx = bisect.bisect_left(self.dates, date)\n",
    "\n",
    "        # init the two bounding points for interpolation \n",
    "        t0, t1 = self.dates[0], self.dates[1] \n",
    "        v0, v1 = self.values[0], self.values[1] \n",
    "        #handle edge case: flat, or extrapolate\n",
    "        if idx == 0:    #do not extrapolate leftward \n",
    "            return v0\n",
    "        elif idx == len(self.dates):    #extrapolate using the last two points\n",
    "            t0, t1 = self.dates[-2], self.dates[-1] \n",
    "            v0, v1 = self.values[-2], self.values[-1] \n",
    "\n",
    "        # otherwise\n",
    "        t0, t1 = self.dates[idx - 1], self.dates[idx] \n",
    "        v0, v1 = self.values[idx - 1], self.values[idx] \n",
    "\n",
    "        e = float((date - t0) / (t1 - t0))\n",
    "        # Perform geometric interpolation \n",
    "        return v0 * pow((v1 / v0), e)\n",
    "\n",
    "    def get_value(self, date: int) -> float:\n",
    "        return self.geometric_interp(date) # self.interpolator(date)\n",
    "\n",
    "class CurveManager:\n",
    "    \"\"\"Singleton class managing curves.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(CurveManager, cls).__new__(cls)\n",
    "            cls._instance.curves = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    def load_curves(self, curve_file):\n",
    "        curves_data = pd.read_csv(curve_file)\n",
    "        for _, row in curves_data.iterrows():\n",
    "            dates = [datetime.strptime(d, \"%Y-%m-%d\") for d in row[\"dates\"].split(\";\")]\n",
    "            values = [float(v) for v in row[\"values\"].split(\";\")]\n",
    "            self.add_curve(SimpleCurve(name=row[\"curve_name\"], dates=dates, values=values))\n",
    "\n",
    "    def read_curves_from_csv(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                curve_name = None\n",
    "                dates = []\n",
    "                values = []\n",
    "\n",
    "                for row in reader:\n",
    "                    if not row:  # Blank row indicates end of current curve\n",
    "                        if curve_name and dates and values:\n",
    "                            curve = SimpleCurve(dates, values)\n",
    "                            self.add_curve(curve_name, dates[0], curve)\n",
    "                            curve_name = None\n",
    "                            dates = []\n",
    "                            values = []\n",
    "                    elif curve_name is None:  # Header row containing curve name\n",
    "                        curve_name = row[0]\n",
    "                    else:  # Data rows containing <date, discount factor>\n",
    "                        date = int(row[0])\n",
    "                        value = float(row[1])\n",
    "                        dates.append(date)\n",
    "                        values.append(value)\n",
    "\n",
    "                # Add the last curve if the file doesn't end with a blank row\n",
    "                if curve_name and dates and values:\n",
    "                    curve = SimpleCurve(dates, values)\n",
    "                    self.add_curve(curve_name, dates[0], curve)\n",
    "                    \n",
    "            logging.info(f\"Successfully read and added curves from CSV: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading curves from CSV file {file_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_curve(self, curve: Curve):\n",
    "        key = (curve.name,)\n",
    "        self.curves[key] = curve\n",
    "        logging.info(f\"Added curve: {curve.name}\")\n",
    "\n",
    "    def get_curve(self, name: str) -> Optional[Curve]:\n",
    "        return self.curves.get((name,))\n",
    "\n",
    "\n",
    "class Scenario:\n",
    "    \"\"\"Class representing a market scenario with BASE, UP, and DOWN perturbed curves.\"\"\"\n",
    "    def __init__(self, name: str, date: datetime, base_curves: Dict[Tuple[str], Curve]):\n",
    "        self.name = name\n",
    "        self.date = date\n",
    "        self.base_curves = base_curves\n",
    "        self.up_curves = {}\n",
    "        self.down_curves = {}\n",
    "        self._generate_perturbations()\n",
    "\n",
    "    def _generate_perturbations(self):\n",
    "        \"\"\"Generates UP and DOWN perturbed curves.\"\"\"\n",
    "        for key, curve in self.base_curves.items():\n",
    "            up_values = [v * 1.1 for v in curve.values]\n",
    "            down_values = [v * 0.9 for v in curve.values]\n",
    "            self.up_curves[key] = SimpleCurve(curve.name, curve.dates, up_values)\n",
    "            self.down_curves[key] = SimpleCurve(curve.name, curve.dates, down_values)\n",
    "\n",
    "\n",
    "class ScenarioManager:\n",
    "    \"\"\"Singleton class managing scenarios.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(ScenarioManager, cls).__new__(cls)\n",
    "            cls._instance.scenarios = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    def create_scenario(self, name: str, date: datetime):\n",
    "        curve_manager = CurveManager()\n",
    "        base_curves = curve_manager.curves\n",
    "        scenario = Scenario(name, date, base_curves)\n",
    "        self.scenarios[(name, date)] = scenario\n",
    "        logging.info(f\"Created scenario: {name} on {date}\")\n",
    "\n",
    "    def load_scenarios(self, scenario_file):\n",
    "        # just the BASE for now\n",
    "        # scenarios_data = pd.read_csv(scenario_file)\n",
    "        self.create_scenario(\"BASE\", self.valuation_date)\n",
    "\n",
    "class Security(ABC):\n",
    "    \"\"\"Abstract class for a financial security.\"\"\"\n",
    "    def __init__(self, security_id: str, attributes: Dict[str, Union[str, float, int]]):\n",
    "        self.security_id = security_id\n",
    "        self.attributes = attributes\n",
    "\n",
    "    @abstractmethod\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Bond(Security):\n",
    "    \"\"\"A simple bond implementation.\"\"\"\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        curve_key = (self.attributes[\"curve_name\"],)\n",
    "        base_curve = scenario.base_curves.get(curve_key)\n",
    "\n",
    "        if not base_curve:\n",
    "            raise ValueError(f\"Curve {curve_key} not found in scenario.\")\n",
    "\n",
    "        cash_flows = self.attributes[\"cash_flows\"]\n",
    "        npv = 0.0\n",
    "        for cash_flow_date, cash_flow_amount in cash_flows:\n",
    "            discount_factor = base_curve.get_value(cash_flow_date)\n",
    "            npv += cash_flow_amount / (1 + discount_factor)\n",
    "        return npv\n",
    "\n",
    "\n",
    "class SecurityManager:\n",
    "    \"\"\"Singleton class managing securities.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(SecurityManager, cls).__new__(cls)\n",
    "            cls._instance.securities = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def set_valuation_date(self, valuation_date):\n",
    "        self.valuation_date = valuation_date\n",
    "\n",
    "    def add_security(self, security: Security):\n",
    "        self.securities[security.security_id] = security\n",
    "        logging.info(f\"Added security: {security.security_id}\")\n",
    "\n",
    "    def load_securities(self, security_file):\n",
    "        securities_data = pd.read_csv(security_file)\n",
    "        for _, row in securities_data.iterrows():\n",
    "            attributes = {\n",
    "                \"curve_name\": row[\"curve_name\"],\n",
    "                \"cash_flows\": [\n",
    "                    (datetime.strptime(d, \"%Y-%m-%d\"), float(a))\n",
    "                    for d, a in zip(row[\"cash_flow_dates\"].split(\";\"), row[\"cash_flow_amounts\"].split(\";\"))\n",
    "                ]\n",
    "            }\n",
    "            self.add_security(Bond(security_id=row[\"security_id\"], attributes=attributes))\n",
    "\n",
    "# Generic Calculation Function\n",
    "def calculate_npv_for_all(security_manager: SecurityManager, scenario_manager: ScenarioManager) -> pd.DataFrame:\n",
    "    data_store = []\n",
    "    for (scenario_name, scenario_date), scenario in scenario_manager.scenarios.items():\n",
    "        for security_id, security in security_manager.securities.items():\n",
    "            try:\n",
    "                base_npv = security.NPV(scenario)\n",
    "                up_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.up_curves))\n",
    "                down_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.down_curves))\n",
    "                data_store.append({\n",
    "                    \"Security ID\": security_id,\n",
    "                    \"Scenario Name\": scenario_name,\n",
    "                    \"Scenario Date\": scenario_date,\n",
    "                    \"NPV_BASE\": base_npv,\n",
    "                    \"NPV_UP\": up_npv,\n",
    "                    \"NPV_DOWN\": down_npv,\n",
    "                })\n",
    "                logging.info(f\"Calculated NPVs for Security: {security_id}, Scenario: {scenario_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error calculating NPV for Security: {security_id}, Scenario: {scenario_name}. Error: {e}\")\n",
    "    return pd.DataFrame(data_store)\n",
    "\n",
    "# Task Dispatcher\n",
    "from os import path\n",
    "class TaskDispatcher:\n",
    "    def __init__(self, config_file: str):\n",
    "        with open(config_file, 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "        self.wk_folder = path.dirname(config_file)\n",
    "        self.valuation_date = datetime.strptime(self.config[\"valuation_date\"], \"%Y-%m-%d\")\n",
    "        self.curve_manager = CurveManager()\n",
    "        self.curve_manager.set_valuation_date(self.valuation_date)\n",
    "        self.scenario_manager = ScenarioManager()\n",
    "        self.scenario_manager.set_valuation_date(self.valuation_date)\n",
    "        self.security_manager = SecurityManager()\n",
    "        self.security_manager.set_valuation_date(self.valuation_date)\n",
    "\n",
    "    def load_curves(self):\n",
    "        curve_file = self.config[\"curve_definition_file\"]\n",
    "        self.curve_manager.read_curves_from_csv(path.join(self.wk_folder, curve_file))\n",
    "\n",
    "    def load_scenarios(self):\n",
    "        scenario_file = self.config[\"scenario_definition_file\"]\n",
    "        self.scenario_manager.load_scenarios(path.join(self.wk_folder, scenario_file))\n",
    "\n",
    "    def load_securities(self):\n",
    "        security_file = self.config[\"security_definition_file\"]\n",
    "        self.security_manager.load_securities(path.join(self.wk_folder, security_file))\n",
    "\n",
    "    def execute_use_case(self):\n",
    "        use_case = self.config[\"use_case\"]\n",
    "        if use_case == \"NPV_CALCULATION\":\n",
    "            results = calculate_npv_for_all(self.security_manager, self.scenario_manager)\n",
    "            results.to_csv(path.join(self.wk_folder, self.config[\"output_file\"]), index=False)\n",
    "            logging.info(f\"Results saved to {self.config['output_file']}\")\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            logging.info(\"Starting Task Dispatcher...\")\n",
    "            self.load_curves()\n",
    "            logging.info(\"Curves loaded\")\n",
    "            self.load_scenarios()\n",
    "            logging.info(\"Scenarios loaded\")\n",
    "            self.load_securities()\n",
    "            logging.info(\"Securities loaded\")\n",
    "            self.execute_use_case()\n",
    "            logging.info(\"Task Dispatcher completed successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Task Dispatcher encountered an error: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the configuration file\n",
    "    config_file = \"C:/dev/Python/rmds/tests/config.json\"\n",
    "    \n",
    "    # Initialize and run the TaskDispatcher\n",
    "    dispatcher = TaskDispatcher(config_file)\n",
    "    dispatcher.run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
