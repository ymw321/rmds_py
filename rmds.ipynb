{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Risk Measure DataSet generation engine codebase\n",
    "\n",
    "This engine contains the following key components:\n",
    "\n",
    "1.\tFirst, a *singleton* object, *CurveManager*, that contains a list of curves identifiable by name and date. Each curve is a specialization of an abstract Curve class and the simplest of which has a vector of double values itemized by dates and when the object is called with a date, an interpolated value is returned. \n",
    "\n",
    "2.\tSecond, a singleton object, *ScenarioManager*, that contains a list of market scenarios identifiable by name and date. Each scenario is constructed by taking the complete list of curves from the CurveManager as the BASE, and perturb each curve up and down in a certain fashion, so that the scenario will contain three lists of the curves: the BASE, the UP perturbed, and the DOWN perturbed.\n",
    "3.\tThirdly, a singleton object, *SecurityManager*, that contains a list of financial securities identifiable by an id. Each security is a specialization of an abstract class Security, constructed from a dictionary of <attribute, value>, and has a function, NPV, that takes a scenario object and returns a value.\n",
    "4.\tLast, a generic function that iterates through each security from the SecurityManager and each scenario from the ScenarioManager, and call the security's NPV function three times to obtain three values for each the perturbations contained in the scenario. The three values are then pushed into a data store with all the relevant identifiers.\n",
    "5.\tPiecing them together is a workflow manager, or *task dispatcher*, to use this code base: it takes a JSON document as a configuration input that instructs about where all the input files such as curve definition and security definition and the scenario definition are located, and indicates what use case the job is tasked with, then it will first pre-process the inputs and construct the three containers, CurveManager, ScenarioManager, and SecurityManager, and dispatch the workflow to the relevant use case. At the end, output the result in the data store to a CSV file.\n",
    "6.\tAnd one more item and most important to complete the picture: *info logging*! we now need a logger through the code so that each step is logged and if there is any exception, error messages are captured into the log. \n",
    "\n",
    "This file is the workflow manager, the *main()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Union, List, Optional, Tuple\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Configure logging\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(\n\u001b[0;32m     14\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_dispatcher.log\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     filemode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m     18\u001b[0m )\n",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Union, List, Optional, Tuple\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Configure logging\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(\n\u001b[0;32m     14\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_dispatcher.log\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     filemode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\Python\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\Python\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# python\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "from datetime import datetime\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Union, List, Optional, Tuple\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"task_dispatcher.log\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Abstract Classes and Singleton Managers\n",
    "\n",
    "class Curve:\n",
    "    \"\"\"Abstract base class for a curve.\"\"\"\n",
    "    def __init__(self, name: str, dates: List[datetime], values: List[float]):\n",
    "        self.name = name\n",
    "        self.dates = dates\n",
    "        self.values = values\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_value(self, date: datetime) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SimpleCurve(Curve):\n",
    "    \"\"\"A simple curve with linear interpolation.\"\"\"\n",
    "    def __init__(self, dates: int, values: float):\n",
    "        self.dates = np.array(dates)\n",
    "        self.values = np.array(values)\n",
    "        self.interpolator = interp1d(self.dates.astype(int), self.values, kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "    def get_value(self, date: int) -> float:\n",
    "        return self.interpolator(date)\n",
    "\n",
    "class CurveManager:\n",
    "    \"\"\"Singleton class managing curves.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(CurveManager, cls).__new__(cls)\n",
    "            cls._instance.curves = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def load_curves(self, curve_file):\n",
    "        curves_data = pd.read_csv(curve_file)\n",
    "        for _, row in curves_data.iterrows():\n",
    "            dates = [datetime.strptime(d, \"%Y-%m-%d\") for d in row[\"dates\"].split(\";\")]\n",
    "            values = [float(v) for v in row[\"values\"].split(\";\")]\n",
    "            self.add_curve(SimpleCurve(name=row[\"curve_name\"], dates=dates, values=values))\n",
    "\n",
    "    def read_curves_from_csv(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                curve_name = None\n",
    "                dates = []\n",
    "                values = []\n",
    "\n",
    "                for row in reader:\n",
    "                    if not row:  # Blank row indicates end of current curve\n",
    "                        if curve_name and dates and values:\n",
    "                            curve = SimpleCurve(dates, values)\n",
    "                            self.add_curve(curve_name, dates[0], curve)\n",
    "                            curve_name = None\n",
    "                            dates = []\n",
    "                            values = []\n",
    "                    elif curve_name is None:  # Header row containing curve name\n",
    "                        curve_name = row[0]\n",
    "                    else:  # Data rows containing <date, discount factor>\n",
    "                        date = int(row[0])\n",
    "                        value = float(row[1])\n",
    "                        dates.append(date)\n",
    "                        values.append(value)\n",
    "\n",
    "                # Add the last curve if the file doesn't end with a blank row\n",
    "                if curve_name and dates and values:\n",
    "                    curve = SimpleCurve(dates, values)\n",
    "                    self.add_curve(curve_name, dates[0], curve)\n",
    "                    \n",
    "            logging.info(f\"Successfully read and added curves from CSV: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading curves from CSV file {file_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_curve(self, curve: Curve):\n",
    "        key = (curve.name,)\n",
    "        self.curves[key] = curve\n",
    "        logging.info(f\"Added curve: {curve.name}\")\n",
    "\n",
    "    def get_curve(self, name: str) -> Optional[Curve]:\n",
    "        return self.curves.get((name,))\n",
    "\n",
    "\n",
    "class Scenario:\n",
    "    \"\"\"Class representing a market scenario with BASE, UP, and DOWN perturbed curves.\"\"\"\n",
    "    def __init__(self, name: str, date: datetime, base_curves: Dict[Tuple[str], Curve]):\n",
    "        self.name = name\n",
    "        self.date = date\n",
    "        self.base_curves = base_curves\n",
    "        self.up_curves = {}\n",
    "        self.down_curves = {}\n",
    "        self._generate_perturbations()\n",
    "\n",
    "    def _generate_perturbations(self):\n",
    "        \"\"\"Generates UP and DOWN perturbed curves.\"\"\"\n",
    "        for key, curve in self.base_curves.items():\n",
    "            up_values = [v * 1.1 for v in curve.values]\n",
    "            down_values = [v * 0.9 for v in curve.values]\n",
    "            self.up_curves[key] = SimpleCurve(curve.name, curve.dates, up_values)\n",
    "            self.down_curves[key] = SimpleCurve(curve.name, curve.dates, down_values)\n",
    "\n",
    "\n",
    "class ScenarioManager:\n",
    "    \"\"\"Singleton class managing scenarios.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(ScenarioManager, cls).__new__(cls)\n",
    "            cls._instance.scenarios = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def create_scenario(self, name: str, date: datetime):\n",
    "        curve_manager = CurveManager()\n",
    "        base_curves = curve_manager.curves\n",
    "        scenario = Scenario(name, date, base_curves)\n",
    "        self.scenarios[(name, date)] = scenario\n",
    "        logging.info(f\"Created scenario: {name} on {date}\")\n",
    "\n",
    "\n",
    "class Security(ABC):\n",
    "    \"\"\"Abstract class for a financial security.\"\"\"\n",
    "    def __init__(self, security_id: str, attributes: Dict[str, Union[str, float, int]]):\n",
    "        self.security_id = security_id\n",
    "        self.attributes = attributes\n",
    "\n",
    "    @abstractmethod\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Bond(Security):\n",
    "    \"\"\"A simple bond implementation.\"\"\"\n",
    "    def NPV(self, scenario: Scenario) -> float:\n",
    "        curve_key = (self.attributes[\"curve_name\"],)\n",
    "        base_curve = scenario.base_curves.get(curve_key)\n",
    "\n",
    "        if not base_curve:\n",
    "            raise ValueError(f\"Curve {curve_key} not found in scenario.\")\n",
    "\n",
    "        cash_flows = self.attributes[\"cash_flows\"]\n",
    "        npv = 0.0\n",
    "        for cash_flow_date, cash_flow_amount in cash_flows:\n",
    "            discount_factor = base_curve.get_value(cash_flow_date)\n",
    "            npv += cash_flow_amount / (1 + discount_factor)\n",
    "        return npv\n",
    "\n",
    "\n",
    "class SecurityManager:\n",
    "    \"\"\"Singleton class managing securities.\"\"\"\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(SecurityManager, cls).__new__(cls)\n",
    "            cls._instance.securities = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def add_security(self, security: Security):\n",
    "        self.securities[security.security_id] = security\n",
    "        logging.info(f\"Added security: {security.security_id}\")\n",
    "\n",
    "\n",
    "# Generic Calculation Function\n",
    "\n",
    "def calculate_npv_for_all(security_manager: SecurityManager, scenario_manager: ScenarioManager) -> pd.DataFrame:\n",
    "    data_store = []\n",
    "    for (scenario_name, scenario_date), scenario in scenario_manager.scenarios.items():\n",
    "        for security_id, security in security_manager.securities.items():\n",
    "            try:\n",
    "                base_npv = security.NPV(scenario)\n",
    "                up_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.up_curves))\n",
    "                down_npv = security.NPV(Scenario(name=scenario.name, date=scenario.date, base_curves=scenario.down_curves))\n",
    "                data_store.append({\n",
    "                    \"Security ID\": security_id,\n",
    "                    \"Scenario Name\": scenario_name,\n",
    "                    \"Scenario Date\": scenario_date,\n",
    "                    \"NPV_BASE\": base_npv,\n",
    "                    \"NPV_UP\": up_npv,\n",
    "                    \"NPV_DOWN\": down_npv,\n",
    "                })\n",
    "                logging.info(f\"Calculated NPVs for Security: {security_id}, Scenario: {scenario_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error calculating NPV for Security: {security_id}, Scenario: {scenario_name}. Error: {e}\")\n",
    "    return pd.DataFrame(data_store)\n",
    "\n",
    "\n",
    "# Task Dispatcher\n",
    "\n",
    "class TaskDispatcher:\n",
    "    def __init__(self, config_file: str):\n",
    "        with open(config_file, 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "        self.curve_manager = CurveManager()\n",
    "        self.scenario_manager = ScenarioManager()\n",
    "        self.security_manager = SecurityManager()\n",
    "\n",
    "    def load_scenarios(self):\n",
    "        scenario_file = self.config[\"scenario_definition_file\"]\n",
    "        scenarios_data = pd.read_csv(scenario_file)\n",
    "        for _, row in scenarios_data.iterrows():\n",
    "            self.scenario_manager.create_scenario(row[\"scenario_name\"], datetime.strptime(row[\"scenario_date\"], \"%Y-%m-%d\"))\n",
    "\n",
    "    def load_securities(self):\n",
    "        security_file = self.config[\"security_definition_file\"]\n",
    "        securities_data = pd.read_csv(security_file)\n",
    "        for _, row in securities_data.iterrows():\n",
    "            attributes = {\n",
    "                \"curve_name\": row[\"curve_name\"],\n",
    "                \"cash_flows\": [\n",
    "                    (datetime.strptime(d, \"%Y-%m-%d\"), float(a))\n",
    "                    for d, a in zip(row[\"cash_flow_dates\"].split(\";\"), row[\"cash_flow_amounts\"].split(\";\"))\n",
    "                ]\n",
    "            }\n",
    "            self.security_manager.add_security(Bond(security_id=row[\"security_id\"], attributes=attributes))\n",
    "\n",
    "    def execute_use_case(self):\n",
    "        use_case = self.config[\"use_case\"]\n",
    "        if use_case == \"NPV_CALCULATION\":\n",
    "            results = calculate_npv_for_all(self.security_manager, self.scenario_manager)\n",
    "            results.to_csv(self.config[\"output_file\"], index=False)\n",
    "            logging.info(f\"Results saved to {self.config['output_file']}\")\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            logging.info(\"Starting Task Dispatcher...\")\n",
    "            self.load_curves()\n",
    "            self.load_scenarios()\n",
    "            self.load_securities()\n",
    "            self.execute_use_case()\n",
    "            logging.info(\"Task Dispatcher completed successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Task Dispatcher encountered an error: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the configuration file\n",
    "    config_file = \"config.json\"\n",
    "    \n",
    "    # Initialize and run the TaskDispatcher\n",
    "    dispatcher = TaskDispatcher(config_file)\n",
    "    dispatcher.run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
